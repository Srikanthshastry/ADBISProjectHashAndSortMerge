{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d65477",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Project 2\n",
    "## Srikanth Shastry\n",
    "## Sheetal Kulkarni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5342ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "pd.set_option('display.max_rows', None)\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "174ae53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(df):\n",
    "    # Process the value in the first column (index 0)\n",
    "    df[0] = df[0].split(\":\")[1].strip()\n",
    "    \n",
    "    # Process the value in the second column (index 1)\n",
    "    df[1] = df[1].split(\":\")[1].strip()\n",
    "    \n",
    "    # Process the value in the third column (index 2)\n",
    "    # Check if the value can be split using \":\" as the delimiter\n",
    "    if len(df[2].split(\":\")) > 1:\n",
    "        # Select the second part (index 1) of the split list\n",
    "        # Remove the last character (semicolon) using [:-1]\n",
    "        df[2] = df[2].split(\":\")[1][:-1].strip()\n",
    "    else:\n",
    "        # If the value cannot be split, assume no trailing semicolon\n",
    "        # Strip the value of leading and trailing spaces\n",
    "        df[2] = df[2][:-1].strip()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f55b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read \"100k.txt\" into a pandas dataframe\n",
    "raw_df = pd.read_csv(\"100k.txt\",\n",
    "                     header=None,\n",
    "                     sep=\"\\t\",\n",
    "                     quotechar='\"',\n",
    "                     skipinitialspace=True,\n",
    "                     names=['subject', 'property', 'object'])\n",
    "\n",
    "# Apply the pre_process_data function to each row of the dataframe\n",
    "raw_df = raw_df.apply(pre_process_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c1414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of dataframes\n",
    "dict_df = dict(tuple(raw_df.groupby('property', as_index=False)))\n",
    "\n",
    "# Remove \"property\" column from every dataframe in the dictionary\n",
    "for key in dict_df:\n",
    "    dict_df[key] = dict_df[key].drop(\"property\", axis=1)\n",
    "    dict_df[key].reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b962e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortMergeJoin(df1, key1, df2, key2):\n",
    "    # Perform Sorting based on keys\n",
    "    sort_df1_On_key1 = df1.sort_values(by=key1, ascending=True)\n",
    "    sort_df2_On_key2 = df2.sort_values(by=key2, ascending=True)\n",
    "    \n",
    "    # Perform merge join\n",
    "    results_df = pd.merge(sort_df1_On_key1, sort_df2_On_key2, left_on=key1, right_on=key2, how='inner')\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cde85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181/71858540.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sortMergeJoin_QueryResult_df.rename(columns={'subject_x_x': 'follows.subject',\n"
     ]
    }
   ],
   "source": [
    "# Sort Merge Join\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform sort merge join between \"follows\" and \"friendOf\" dataframes\n",
    "followsObj_friendOfSubj_smj_df = sortMergeJoin(\n",
    "    dict_df[\"follows\"], \"object\",\n",
    "    dict_df[\"friendOf\"], \"subject\"\n",
    ")\n",
    "\n",
    "# Perform sort merge join between \"likes\" and \"hasReview\" dataframes\n",
    "likesObj_hasReviewSubj_smj_df = sortMergeJoin(\n",
    "    dict_df[\"likes\"], \"object\",\n",
    "    dict_df[\"hasReview\"], \"subject\"\n",
    ")\n",
    "\n",
    "# Perform sort merge join between \"followsObj_friendOfSubj_smj_df\" and \"likesObj_hasReviewSubj_smj_df\" dataframes\n",
    "friendsOfObj_likesSubj_smj_df = sortMergeJoin(\n",
    "    followsObj_friendOfSubj_smj_df, \"object_y\",\n",
    "    likesObj_hasReviewSubj_smj_df, \"subject_x\"\n",
    ")\n",
    "\n",
    "# Extract the desired columns from the joined dataframe\n",
    "sortMergeJoin_QueryResult_df = friendsOfObj_likesSubj_smj_df[[\"subject_x_x\",\n",
    "                                                               \"object_x_x\",\n",
    "                                                               \"object_y_x\",\n",
    "                                                               \"object_x_y\",\n",
    "                                                               \"object_y_y\"]]\n",
    "\n",
    "# Rename the columns of the result dataframe\n",
    "sortMergeJoin_QueryResult_df.rename(columns={'subject_x_x': 'follows.subject',\n",
    "                                             'object_x_x': 'follows.object',\n",
    "                                             'object_y_x': 'friendOf.object',\n",
    "                                             'object_x_y': 'likes.object',\n",
    "                                             'object_y_y': 'hasReview.object'}, inplace=True)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b51c90d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Complexity of Sort merge Join: 6.768456220626831 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Time Complexity of Sort merge Join: %s seconds\" %(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5c76fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashJoin(df1, key1, df2, key2):\n",
    "    \n",
    "    # Apply hash function on key columns of df1 and df2\n",
    "    df1[\"hash_key\"] = df1[key1].apply(hash)\n",
    "    df2[\"hash_key\"] = df2[key2].apply(hash)\n",
    "    \n",
    "    # Partition df1 based on hash keys\n",
    "    df1_partitions = dict(tuple(df1.groupby('hash_key')))\n",
    "    \n",
    "    # Reset the index of each partition\n",
    "    for key in df1_partitions:\n",
    "        df1_partitions[key].reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Get the keys present in df1 partitions\n",
    "    dictKeys = df1_partitions.keys()\n",
    "    \n",
    "    # Initialize an empty list to store the joined partitions\n",
    "    resultAsList = []\n",
    "    \n",
    "    # Iterate over rows of df2\n",
    "    for i in range(len(df2)):\n",
    "        # Check if the hash key of the row is present in df1 partitions\n",
    "        if df2.iloc[i]['hash_key'] in dictKeys:\n",
    "            key = df2.iloc[i]['hash_key']\n",
    "            joinRow = df2.iloc[[i]]\n",
    "            # Perform left join between partition and joinRow based on hash key\n",
    "            joinedRow = pd.merge(df1_partitions[key], joinRow, on='hash_key', how='left')\n",
    "            resultAsList.append(joinedRow.to_dict('list'))\n",
    "    \n",
    "    # Convert the list of dictionaries to a list of dataframes\n",
    "    listOfJoinedPartitions = []\n",
    "    for dictionary in resultAsList:\n",
    "        listOfJoinedPartitions.append(pd.DataFrame(dictionary))\n",
    "    \n",
    "    # Concatenate the dataframes in the list\n",
    "    finalDf = pd.concat(listOfJoinedPartitions)\n",
    "    \n",
    "    # Drop the hash_key column from the final dataframe\n",
    "    finalDf = finalDf.drop('hash_key', axis=1)\n",
    "    \n",
    "    return finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c64fdcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181/1922242578.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hashJoin_QueryResult_df.rename(columns={'subject_x_x': 'follows.subject',\n"
     ]
    }
   ],
   "source": [
    "#Hash Join\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform hash join between \"follows\" and \"friendOf\" dataframes\n",
    "followsObj_friendOfSubj_hj_df = hashJoin(\n",
    "    dict_df['follows'], 'object',\n",
    "    dict_df['friendOf'], 'subject'\n",
    ")\n",
    "\n",
    "# Perform hash join between \"likes\" and \"hasReview\" dataframes\n",
    "likesObj_hasReviewSubj_hj_df = hashJoin(\n",
    "    dict_df['likes'], 'object',\n",
    "    dict_df['hasReview'], 'subject'\n",
    ")\n",
    "\n",
    "# Perform hash join between \"followsObj_friendOfSubj_hj_df\" and \"likesObj_hasReviewSubj_hj_df\" dataframes\n",
    "friendsOfObj_likesSubj_hj_df = hashJoin(\n",
    "    followsObj_friendOfSubj_hj_df, 'object_y',\n",
    "    likesObj_hasReviewSubj_hj_df, 'subject_x'\n",
    ")\n",
    "\n",
    "# Extract the desired columns from the joined dataframe\n",
    "hashJoin_QueryResult_df = friendsOfObj_likesSubj_hj_df[[\"subject_x_x\",\n",
    "                                                        \"object_x_x\",\n",
    "                                                        \"object_y_x\",\n",
    "                                                        \"object_x_y\",\n",
    "                                                        \"object_y_y\"]]\n",
    "\n",
    "# Rename the columns of the result dataframe\n",
    "hashJoin_QueryResult_df.rename(columns={'subject_x_x': 'follows.subject',\n",
    "                                        'object_x_x': 'follows.object',\n",
    "                                        'object_y_x': 'friendOf.object',\n",
    "                                        'object_x_y': 'likes.object',\n",
    "                                        'object_y_y': 'hasReview.object'}, inplace=True)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0d514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Complexity of Hash Join: 204.03605151176453 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Time Complexity of Hash Join: %s seconds\" %(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0932124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Hash-join\n",
    "\n",
    "def improvedHashJoin(df1, key1, df2, key2):\n",
    "    # Apply hash function on key columns of df1 and df2\n",
    "    df1[\"hash_key\"] = df1[key1].apply(hash)\n",
    "    df2[\"hash_key\"] = df2[key2].apply(hash)\n",
    "    \n",
    "    # Partition df1 based on hash keys\n",
    "    df1_partitions = dict(tuple(df1.groupby('hash_key')))\n",
    "    \n",
    "    # Reset the index of each partition in df1\n",
    "    for key in df1_partitions:\n",
    "        df1_partitions[key].reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Partition df2 based on hash keys\n",
    "    df2_partitions = dict(tuple(df2.groupby('hash_key')))\n",
    "    \n",
    "    # Reset the index of each partition in df2\n",
    "    for key in df2_partitions:\n",
    "        df2_partitions[key].reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Initialize an empty list to store the joined partitions\n",
    "    resultAsList = []\n",
    "    \n",
    "    # Perform join between partitions with matching hash keys\n",
    "    for key_2 in df2_partitions:\n",
    "        for key_1 in df1_partitions:\n",
    "            if key_1 == key_2:\n",
    "                joinedPartitions = pd.merge(df1_partitions[key_1], df2_partitions[key_2], on='hash_key', how='left')\n",
    "                resultAsList.append(joinedPartitions.to_dict('list'))\n",
    "    \n",
    "    # Convert the list of dictionaries to a list of dataframes\n",
    "    listOfJoinedPartitions = []\n",
    "    for dictionary in resultAsList:\n",
    "        listOfJoinedPartitions.append(pd.DataFrame(dictionary))\n",
    "    \n",
    "    # Concatenate the dataframes in the list\n",
    "    finalDf = pd.concat(listOfJoinedPartitions)\n",
    "    \n",
    "    # Drop the hash_key column from the final dataframe\n",
    "    finalDf = finalDf.drop('hash_key', axis=1)\n",
    "    \n",
    "    return finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51dbbc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181/3201583677.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  improvedHashJoin_QueryResult_df.rename(columns={'subject_x_x': 'follows.subject',\n"
     ]
    }
   ],
   "source": [
    "#Improved Hash Join Results\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform improved hash join between \"follows\" and \"friendOf\" dataframes\n",
    "followsObj_friendOfSubj_ihj_df = improvedHashJoin(\n",
    "    dict_df['follows'], 'object',\n",
    "    dict_df['friendOf'], 'subject'\n",
    ")\n",
    "\n",
    "# Perform improved hash join between \"likes\" and \"hasReview\" dataframes\n",
    "likesObj_hasReviewSubj_ihj_df = improvedHashJoin(\n",
    "    dict_df['likes'], 'object',\n",
    "    dict_df['hasReview'], 'subject'\n",
    ")\n",
    "\n",
    "# Perform improved hash join between \"followsObj_friendOfSubj_ihj_df\" and \"likesObj_hasReviewSubj_ihj_df\" dataframes\n",
    "friendsOfObj_likesSubj_ihj_df = improvedHashJoin(\n",
    "    followsObj_friendOfSubj_ihj_df, 'object_y',\n",
    "    likesObj_hasReviewSubj_ihj_df, 'subject_x'\n",
    ")\n",
    "\n",
    "# Extract the desired columns from the joined dataframe\n",
    "improvedHashJoin_QueryResult_df = friendsOfObj_likesSubj_ihj_df[[\"subject_x_x\",\n",
    "                                                                \"object_x_x\",\n",
    "                                                                \"object_y_x\",\n",
    "                                                                \"object_x_y\",\n",
    "                                                                \"object_y_y\"]]\n",
    "\n",
    "# Rename the columns of the result dataframe\n",
    "improvedHashJoin_QueryResult_df.rename(columns={'subject_x_x': 'follows.subject',\n",
    "                                                'object_x_x': 'follows.object',\n",
    "                                                'object_y_x': 'friendOf.object',\n",
    "                                                'object_x_y': 'likes.object',\n",
    "                                                'object_y_y': 'hasReview.object'}, inplace=True)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f0347b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Complexity of Improved Hash Join: 65.34886622428894 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Time Complexity of Improved Hash Join: %s seconds\" %(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
